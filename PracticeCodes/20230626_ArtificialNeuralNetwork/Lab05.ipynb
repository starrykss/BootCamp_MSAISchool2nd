{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e87202a",
   "metadata": {},
   "source": [
    "# Lab 05. 선형 분류 : 로지스틱 회귀(Logistic Regression)\n",
    "---\n",
    "\n",
    "- 파이썬과 파이토치를 활용한 로지스틱 회귀 모델을 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e88db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c790614c",
   "metadata": {},
   "source": [
    "## 데이터셋 만들기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7130380",
   "metadata": {},
   "source": [
    "- `make_classificaiton` 함수를 사용하여 무작위로 데이터셋을 만들어본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfcd6744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02439857 -0.57540077  1.26796049 -1.42222965 -0.9629849 ]\n",
      " [-1.07638119  0.3872175   1.08299994 -0.67379011 -2.65098736]\n",
      " [-1.12984986 -0.26922916  1.12735009 -0.82383687 -1.70574586]\n",
      " ...\n",
      " [-0.53797853  0.26401859 -0.48915618  0.4664446  -1.57451325]\n",
      " [ 0.01920342  0.9761859  -0.14717165 -1.51725386  2.31873002]\n",
      " [-0.37051336  0.93603022 -0.62133172 -0.23084897  1.66473405]] [0 0 0 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "x, y = make_classification(\n",
    "    n_samples=3000,         # 생성할 데이터 수 \n",
    "    n_features=5,           # 독립 변수 수 (입력 변수에 사용되는 변수) / 종속 변수 -> 라벨 \n",
    "    n_informative=2,        # 독립 변수 수 중에서 실제로 유의미한 의미가 있는 변수 계수 \n",
    "    n_redundant=0,          # 독립 변수 중에 다른 독립 변수로부터 파생된 불필요한 독립 변수 계수 \n",
    "    n_clusters_per_class=1, # 클래스당 클러스터 계수 \n",
    "    random_state=42         # 난수 생성 발생기의 시드값 \n",
    ")\n",
    "\n",
    "print(x, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5c722ad",
   "metadata": {},
   "source": [
    "## 데이터셋을 Train Set과 Test Set으로 나누기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "633cb678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train >>  2400\n",
      "x_test >>  600\n",
      "y_train >>  2400\n",
      "y_test >>  600\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"x_train >> \" , len(x_train))\n",
    "print(\"x_test >> \", len(x_test))\n",
    "print(\"y_train >> \", len(y_train))\n",
    "print(\"y_test >> \", len(y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "903fa3e7",
   "metadata": {},
   "source": [
    "## 파이토치의 Dataset과 Dataloader를 사용하기 위한 Custom Dataset 구현 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca35b43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomDataset(Dataset) :\n",
    "    def __init__(self, x, y) : \n",
    "        # 텐서 형태로 변환 \n",
    "        self.x = torch.tensor(x, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index) :\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "    \n",
    "    def __len__(self) : \n",
    "        return len(self.x)\n",
    "\n",
    "# 데이터셋 정의     \n",
    "train_dataset = MyCustomDataset(x_train, y_train)\n",
    "test_dataset = MyCustomDataset(x_test, y_test)\n",
    "\n",
    "# 데이터 로드 정의 \n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# ########## 디버깅 코드 ##############\n",
    "# test = MyCustomDataset(x_test, y_test)\n",
    "# for i in test : \n",
    "#     print(i)\n",
    "########## 디버깅 코드 ##############\n",
    "# for index, (datas, lables) in enumerate(test_loader) : \n",
    "#     print(index, datas, lables)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3fd700d3",
   "metadata": {},
   "source": [
    "## 모델 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26dae41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(\n",
      "  (linear): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LogisticRegression(nn.Module) : \n",
    "    def __init__(self, input_dim) : \n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        out = self.linear(x)\n",
    "        out = torch.sigmoid(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = LogisticRegression(input_dim=5)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30a1c4af",
   "metadata": {},
   "source": [
    "## 모델을 학습시키기 전에 학습에 필요한 Loss Function, Optimizer 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62bec6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: adamp in c:\\users\\kss34\\anaconda3\\envs\\pytorchpractice\\lib\\site-packages (0.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install adamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10e14d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 1e-05\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from adamp import SGDP\n",
    "\n",
    "\"\"\"\n",
    "# define your params\n",
    "optimizer = SGDP(params, lr=0.1, weight_decay=1e-5, momentum=0.9, nesterov=True)\n",
    "\"\"\"\n",
    "\n",
    "criterion = nn.BCELoss()    # 사용한 이유는 0과 1 분류(이진 분류)하기 떄문 \n",
    "# optimizer = SGDP(model.parameters(), lr=0.25, weight_decay=1e-5, momentum=0.9, nesterov=True)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-5, momentum=0.9, nesterov=True)\n",
    "\n",
    "print(optimizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83f7db7b",
   "metadata": {},
   "source": [
    "## Tarin Loop 구현 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e16bc739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/100], Loss : [0.4751]\n",
      "Epoch : [11/100], Loss : [0.2311]\n",
      "Epoch : [21/100], Loss : [0.1242]\n",
      "Epoch : [31/100], Loss : [0.2554]\n",
      "Epoch : [41/100], Loss : [0.3022]\n",
      "Epoch : [51/100], Loss : [0.1658]\n",
      "Epoch : [61/100], Loss : [0.2496]\n",
      "Epoch : [71/100], Loss : [0.1219]\n",
      "Epoch : [81/100], Loss : [0.2615]\n",
      "Epoch : [91/100], Loss : [0.1628]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs) : \n",
    "    for inputs, targets in train_loader : \n",
    "        # print(targets)\n",
    "        # print(\"unsqueeze >> \", targets.unsqueeze(1))\n",
    "        # optimizer 초기화 진행 \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0 :\n",
    "        print(f\"Epoch : [{epoch+1}/{num_epochs}], Loss : [{loss.item():.4f}]\")\n",
    "        \n",
    "    \"\"\"\n",
    "    SGDP\n",
    "    Epoch : [1/100], Loss : [0.2932]\n",
    "    Epoch : [11/100], Loss : [0.2758]\n",
    "    Epoch : [21/100], Loss : [0.1802]\n",
    "    Epoch : [31/100], Loss : [0.4343]\n",
    "    Epoch : [41/100], Loss : [0.1413]\n",
    "    Epoch : [51/100], Loss : [0.2233]\n",
    "    Epoch : [61/100], Loss : [0.2452]\n",
    "    Epoch : [71/100], Loss : [0.1318]\n",
    "    Epoch : [81/100], Loss : [0.2263]\n",
    "    Epoch : [91/100], Loss : [0.2263]\n",
    "    \n",
    "    SGD \n",
    "    Epoch : [1/100], Loss : [0.3412]\n",
    "    Epoch : [11/100], Loss : [0.2807]\n",
    "    Epoch : [21/100], Loss : [0.3580]\n",
    "    Epoch : [31/100], Loss : [0.3004]\n",
    "    Epoch : [41/100], Loss : [0.2017]\n",
    "    Epoch : [51/100], Loss : [0.2862]\n",
    "    Epoch : [61/100], Loss : [0.2308]\n",
    "    Epoch : [71/100], Loss : [0.2103]\n",
    "    Epoch : [81/100], Loss : [0.2252]\n",
    "    Epoch : [91/100], Loss : [0.2543]\n",
    "    \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49270e9b",
   "metadata": {},
   "source": [
    "## 평가 코드 작성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d04daeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device >>  cpu\n",
      "Acc >> 48%\n"
     ]
    }
   ],
   "source": [
    "# Device on GPU or CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device >> \", device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad() : \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for test_inputs, test_targets in test_loader : \n",
    "#         print(test_inputs, test_targets)\n",
    "        test_input, test_target = test_inputs.to(device), test_targets.to(device)\n",
    "        outputs_test = model(test_input)\n",
    "        _, pred_test = torch.max(outputs_test, 1)\n",
    "        total += test_targets.size(0)\n",
    "        correct += (pred_test == test_targets).sum().item()\n",
    "        \n",
    "    print(\"Acc >> %d%%\"%(100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchPractice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
