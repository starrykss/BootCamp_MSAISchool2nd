{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01. 음성 데이터 -> waveshow / stft / MelSpectrogram 이미지 학습하기\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "class CustomDataset(Dataset) :\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        # data_dir = ./data/train/\n",
    "        self.data_dir = glob.glob(os.path.join(data_dir, \"*\", \"*.png\"))\n",
    "        self.transform = transform\n",
    "        self.label_dict = {\"MelSepctrogram\" : 0 , \"STFT\" : 1, \"waveshow\" : 2}\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image_path = self.data_dir[item]\n",
    "        # image_path >>> .\\data\\train\\waveshow\\rock.00006_augmented_noise.png\n",
    "        image = Image.open(image_path)\n",
    "        image = image.convert(\"RGB\")\n",
    "        label_name = image_path.split(\"\\\\\")[1]\n",
    "        label = self.label_dict[label_name]\n",
    "\n",
    "        if self.transform is not None :\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image ,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class ImageMove :\n",
    "    def __init__(self, org_folder):\n",
    "        self.org_folder = org_folder\n",
    "    def move_images(self):\n",
    "        file_path_list = glob.glob(os.path.join(self.org_folder, \"*\", \"*\" , \"*.png\"))\n",
    "        for file_path in file_path_list :\n",
    "            folder_name = file_path.split(\"\\\\\")[1]\n",
    "            if folder_name == \"MelSepctrogram\" :\n",
    "                shutil.move(file_path, \"./ex_dataset/data/MelSepctrogram\")\n",
    "            elif folder_name == \"STFT\" :\n",
    "                shutil.move(file_path, \"./ex_dataset/data/STFT\")\n",
    "            elif folder_name == \"waveshow\" :\n",
    "                shutil.move(file_path, \"./ex_dataset/data/waveshow\")\n",
    "\n",
    "# test = ImageMove(\"./final_data/\")\n",
    "# test.move_images()\n",
    "\n",
    "class ImageDataMove :\n",
    "    def __init__(self, org_dir, train_dir, val_dir):\n",
    "        self.org_dir = org_dir\n",
    "        self.train_dir = train_dir\n",
    "        self.val_dir = val_dir\n",
    "\n",
    "    def move_images(self):\n",
    "        # File Path List\n",
    "        file_path_list01 = glob.glob(os.path.join(self.org_dir, \"*\", \"waveshow\", \"*.png\"))\n",
    "        file_path_list02 = glob.glob(os.path.join(self.org_dir, \"*\", \"STFT\", \"*.png\"))\n",
    "        file_path_list03 = glob.glob(os.path.join(self.org_dir, \"*\", \"MelSepctrogram\", \"*.png\"))\n",
    "\n",
    "        # Data Split\n",
    "        wa_train_data_list , wa_val_data_list = train_test_split(file_path_list01, test_size=0.2)\n",
    "        st_train_data_list , st_val_data_list = train_test_split(file_path_list02, test_size=0.2)\n",
    "        ms_train_data_list , ms_val_data_list = train_test_split(file_path_list03, test_size=0.2)\n",
    "\n",
    "        # File Move\n",
    "        self.move_file(wa_train_data_list, os.path.join(self.train_dir, \"waveshow\"))\n",
    "        self.move_file(wa_val_data_list, os.path.join(self.val_dir, \"waveshow\"))\n",
    "        self.move_file(st_train_data_list, os.path.join(self.train_dir, \"STFT\"))\n",
    "        self.move_file(st_val_data_list, os.path.join(self.val_dir, \"STFT\"))\n",
    "        self.move_file(ms_train_data_list, os.path.join(self.train_dir, \"MelSepctrogram\"))\n",
    "        self.move_file(ms_val_data_list, os.path.join(self.val_dir, \"MelSepctrogram\"))\n",
    "\n",
    "    def move_file(self, file_list, mov_dir):\n",
    "        os.makedirs(mov_dir, exist_ok=True)\n",
    "        for file_path in file_list:\n",
    "            shutil.move(file_path, mov_dir)\n",
    "\n",
    "# org_dir = \"ex_dataset\"\n",
    "# train_dir = \"./data/train\"\n",
    "# val_dir = \"./data/val\"\n",
    "#\n",
    "# move_temp = ImageDataMove(org_dir, train_dir, val_dir)\n",
    "# move_temp.move_images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lion_pytorch in c:\\miniconda\\envs\\ms_ai_school\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: torch>=1.6 in c:\\miniconda\\envs\\ms_ai_school\\lib\\site-packages (from lion_pytorch) (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\miniconda\\envs\\ms_ai_school\\lib\\site-packages (from torch>=1.6->lion_pytorch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\miniconda\\envs\\ms_ai_school\\lib\\site-packages (from torch>=1.6->lion_pytorch) (4.6.3)\n",
      "Requirement already satisfied: sympy in c:\\miniconda\\envs\\ms_ai_school\\lib\\site-packages (from torch>=1.6->lion_pytorch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\miniconda\\envs\\ms_ai_school\\lib\\site-packages (from torch>=1.6->lion_pytorch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\miniconda\\envs\\ms_ai_school\\lib\\site-packages (from torch>=1.6->lion_pytorch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\miniconda\\envs\\ms_ai_school\\lib\\site-packages (from jinja2->torch>=1.6->lion_pytorch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\miniconda\\envs\\ms_ai_school\\lib\\site-packages (from sympy->torch>=1.6->lion_pytorch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lion_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vgg11, VGG11_Weights, resnet50, resnet18\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from Lab01_CustomDataset import CustomDataset\n",
    "from Lab02_CustomDataset import CustomDataset_ex02\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_loader, val_loader, epochs, DEVICE, optimizer, criterion) :\n",
    "    best_val_acc = 0.0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    print(\"Train...\")\n",
    "\n",
    "    for epoch in range(epochs) :\n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "        val_acc = 0.0\n",
    "        train_acc = 0.0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        # tqdm\n",
    "        train_loader_iter = tqdm(train_loader, desc=f\"Epoch {epoch +1}/{epochs}\", leave=False)\n",
    "\n",
    "        for i, (data, target) in enumerate(train_loader_iter) :\n",
    "            data = data.to(DEVICE)\n",
    "            target = target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # Acc\n",
    "            _, pred = torch.max(output, 1)\n",
    "            train_acc += (pred == target).sum().item()\n",
    "\n",
    "            # Print the loss\n",
    "            if i % 10 == 9 :\n",
    "                train_loader_iter.set_postfix({\"Loss\" : loss.item()})\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = train_acc / len(train_loader.dataset)\n",
    "\n",
    "        # Eval\n",
    "        model.eval()\n",
    "        with torch.no_grad() :\n",
    "            for data, target in val_loader :\n",
    "                data = data.to(DEVICE)\n",
    "                target = target.to(DEVICE)\n",
    "\n",
    "                outputs = model(data)\n",
    "                pred = outputs.argmax(dim=1, keepdim=True)\n",
    "                val_acc += pred.eq(target.view_as(pred)).sum().item()\n",
    "                val_loss += criterion(outputs, target).item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = val_acc / len(val_loader.dataset)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        # save the model with the best val acc\n",
    "        if val_acc > best_val_acc :\n",
    "            torch.save(model.state_dict(), '01_ex_best.pt')\n",
    "            best_val_acc = val_acc\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], \"\n",
    "              f\"Train Loss : {train_loss :.4f}, \"\n",
    "              f\"Train Acc : {train_acc:.4f}, \"\n",
    "              f\"Val Loss : {val_loss :.4f},\"\n",
    "              f\" Val Acc : {val_acc :.4f}  \")\n",
    "\n",
    "    return model, train_losses, val_losses, train_accs, val_accs\n",
    "\n",
    "# Train Loss : 0.4077, Train Acc : 0.8465,\n",
    "def main() :\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # DEVICE_MPS = torch.device(\"mps\")    # Mac m1/m2\n",
    "\n",
    "    # model = vgg11(weights=VGG11_Weights.DEFAULT)\n",
    "    model = resnet18(pretrained=True)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, 10)\n",
    "\n",
    "    # VGG\n",
    "    # num_feature = model.classifier[6].in_features\n",
    "    # model.classifier[6] = nn.Linear(num_feature, 3)\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "\n",
    "    \"\"\"\n",
    "    # transforms\n",
    "    1. aug \n",
    "    2. ToTensor \n",
    "    3. Normalize\n",
    "    \"\"\"\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # Dataset\n",
    "    train_dataset = CustomDataset_ex02(\"./data_art/train/\", transform=train_transform)\n",
    "    val_dataset = CustomDataset_ex02(\"./data_art/val/\", transform=val_transform)\n",
    "\n",
    "    # Dataloader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=100, num_workers=4,\n",
    "                            pin_memory=True, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=100, num_workers=4,\n",
    "                            pin_memory=True, shuffle=False)\n",
    "    # import time\n",
    "    # import math\n",
    "    # test = time.time()\n",
    "    # math.factorial(100000)\n",
    "    # test01 = time.time()\n",
    "    # print(f\"{test01 - test :.5f} sec\")\n",
    "\n",
    "    from lion_pytorch import Lion    # 라이언 옵티마이저 사용\n",
    "\n",
    "    epochs = 20\n",
    "    criterion = CrossEntropyLoss().to(DEVICE)\n",
    "    optimizer = AdamW(model.parameters(), lr=0.001, weight_decay=1e-2)\n",
    "\n",
    "    train(model, train_loader, val_loader, epochs, DEVICE, optimizer, criterion)\n",
    "\n",
    "if __name__ == \"__main__\" :\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MS_AI_SCHOOL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
